{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0cbebca",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50181630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "#normalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#classification\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, cross_val_predict, KFold, cross_validate\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1063a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool columns in dataframe\n",
    "global bool_columns\n",
    "bool_columns = ['Smokes','Hormonal Contraceptives', 'IUD', 'STDs',\n",
    "                'STDs:condylomatosis', 'STDs:cervical condylomatosis',\n",
    "                'STDs:vaginal condylomatosis', 'STDs:vulvo-perineal condylomatosis',\n",
    "                'STDs:syphilis', 'STDs:pelvic inflammatory disease', \n",
    "                'STDs:genital herpes', 'STDs:molluscum contagiosum',\n",
    "                'STDs:AIDS', 'STDs:HIV', 'STDs:Hepatitis B', 'STDs:HPV',\n",
    "                'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403503b8",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe532326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanImputation(df):\n",
    "    \"\"\"Data imputation using mean/mode of columns\n",
    "    Following the methods described in: Razaliet al. (2020).\n",
    "    Risk Factors of Cervical Cancer using Classification in Data Mining.\n",
    "    Journal of Physics: Conference Series. 1529. 022102. 10.1088/1742-6596/1529/2/022102.\n",
    "\n",
    "    Missing values for attribute that have integer data type were filled using the sample mean\n",
    "    while boolean were filled using the sample mode.\n",
    "    \"\"\"\n",
    "        \n",
    "    # replace NaN with mode for columns with dtype bool\n",
    "    for label, col in df.iteritems():\n",
    "        if label in bool_columns:\n",
    "            columns_mode = col.mode()\n",
    "            # method 1\n",
    "            df[label] = col.fillna(columns_mode[0])\n",
    "\n",
    "            #convert column to bool while we're at it\n",
    "            df[label] = df[label].astype('bool')\n",
    "\n",
    "    float_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "    # replace NaN with mean for columns with dtype float\n",
    "    for col in float_columns:\n",
    "        columns_mean = df[col].mean()\n",
    "        df[col] = df[col].fillna(columns_mean)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e065801",
   "metadata": {},
   "source": [
    "# Custom transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195f52e",
   "metadata": {},
   "source": [
    "## Data imputation\n",
    "\n",
    "Method 1: MeanImputationTransformer\n",
    "Following the methods described in:\n",
    "Razali, Nazim & Mostafa, Salama & Mustapha, Aida & Abd Wahab, Mohd Helmy & Ibrahim, Nurul. (2020). Risk Factors of Cervical Cancer using Classification in Data Mining. Journal of Physics: Conference Series. 1529. 022102. 10.1088/1742-6596/1529/2/022102. \n",
    "\n",
    "\"Missing values for attribute that have integer data type were filled using the sample mean while boolean\n",
    "were filled using the sample mode.\"\n",
    "\n",
    "Method 2: UniqueValueImputationTransformer\n",
    "Sets unique value -99 everywhere where data is missing. Value is chosen as it doesn't have any real-life meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d100b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanImputationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        #print(\"Mean value imputation called.\")\n",
    "        X_ = X.copy() # create copy to avoid changes to original dataset\n",
    "        X_ = meanImputation(X_)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca48fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqueValueImputationTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        #print(\"Unique value imputation called.\")\n",
    "        X_ = X.copy() # create copy to avoid changes to original dataset\n",
    "        X_ = X_.fillna(-99)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7ecdfa",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bffc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://archive-beta.ics.uci.edu/ml/datasets/cervical+cancer+risk+factors\n",
    "\"\"\"\n",
    "The dataset was collected at 'Hospital Universitario de Caracas' in Caracas, Venezuela.\n",
    "The dataset comprises demographic information, habits, and historic medical records of 858 patients.\n",
    "Several patients decided not to answer some of the questions because of privacy concerns (missing values).\n",
    "\"\"\"\n",
    "\n",
    "rf = pd.read_csv('risk_factors_cervical_cancer.csv',encoding='utf8')\n",
    "#rf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a76d55",
   "metadata": {},
   "source": [
    "# Covert data to usable datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc42aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with NaN\n",
    "rf = rf.replace('?',np.nan)\n",
    "\n",
    "# covert everything to float64, some classes will be converted to bool once missing values are taken care of\n",
    "for label, col in rf.iteritems():\n",
    "    rf[label] = pd.to_numeric(col, errors='coerce')\n",
    "\n",
    "#TODO: some things are still int after this and object types get transformed to bool automatically. But NaN values\n",
    "#are not falsly converted to True so that should be okay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d83df",
   "metadata": {},
   "source": [
    "# Examine data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55307b39",
   "metadata": {},
   "source": [
    "## Check missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "183f3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = rf.isnull().sum() * 100 / len(rf)\n",
    "missing_value_df = pd.DataFrame({'column_name': rf.columns,\n",
    "                                 'percent_missing': percent_missing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with more than 20% missing\n",
    "selection_columns = missing_value_df.loc[missing_value_df['percent_missing'] >= 20].iloc[:, 0]\n",
    "\n",
    "for col in selection_columns:\n",
    "    rf = rf.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e4535",
   "metadata": {},
   "source": [
    "## Check missing values per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8bda08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 number of rows were removed\n"
     ]
    }
   ],
   "source": [
    "missing_count = []\n",
    "for idx in range(len(rf)):\n",
    "    missing = rf.loc[[idx]].isna().sum().sum()\n",
    "    missing_count.append(missing)\n",
    "\n",
    "removed = 0\n",
    "for idx, val in enumerate(missing_count):\n",
    "    # Remove all rows where more than 15% of the data are missing\n",
    "    # If 20% is chosen, 106 patients are excluded\n",
    "    if val >= len(rf.columns)*0.15:\n",
    "        rf = rf.drop(idx)\n",
    "        removed+=1\n",
    "print(\"{} number of rows were removed\".format(removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e6b478",
   "metadata": {},
   "source": [
    "## Investigate class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b74d25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if STDs (number) and STDs: Number of diagnosis are the same\n",
    "STD_comparison = np.where((rf['STDs (number)']==rf['STDs: Number of diagnosis']), True, False)\n",
    "\n",
    "# check manual calculation with STDs(number) if STDS (number) and STDs: Number of diagnosis not the same\n",
    "if not STD_comparison.all():\n",
    "    # create a new column with the sum of all STDs\n",
    "    rf['STDs (number manual)'] = (rf['STDs:condylomatosis'] + rf['STDs:cervical condylomatosis'] +\n",
    "        rf['STDs:vaginal condylomatosis'] + rf['STDs:vulvo-perineal condylomatosis'] +\n",
    "        rf['STDs:syphilis'] + rf['STDs:pelvic inflammatory disease'] +\n",
    "        rf['STDs:genital herpes'] + rf['STDs:molluscum contagiosum'] +\n",
    "        rf['STDs:AIDS'] + rf['STDs:HIV'] +\n",
    "        rf['STDs:Hepatitis B'] + rf['STDs:HPV'])\n",
    "    \n",
    "    # if they're the same drop the new column again\n",
    "    manual_comp = np.where((rf['STDs (number)']==rf['STDs (number manual)']), True, False)\n",
    "    if manual_comp.all():\n",
    "        rf = rf.drop(['STDs (number manual)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ff1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't know exactly what this column\n",
    "# as our goal is to create a transparent model we decided to exclude the column\n",
    "rf = rf.drop(['STDs: Number of diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8e7c2",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913c2f7",
   "metadata": {},
   "source": [
    "## Explainable boosting classifier metrics\n",
    "## For pipelines with different oversampling and imputation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbcdbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in features and target variable\n",
    "feature_cols = rf.columns[0:len(rf.columns)-4]\n",
    "X = rf[feature_cols] # Features\n",
    "y = rf.Biopsy # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e454438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = None # default 5-fold cross validation\n",
    "#cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "#cv = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe0cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for SMOTE oversampling\n",
    "# for reproducibility purposes\n",
    "seed = 100\n",
    "# SMOTE number of neighbors\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5732e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline 1 using unique value imputation and random oversampling\n",
    "pipe_1 = make_pipeline(SimpleImputer(fill_value=-99), RandomOverSampler('minority'), RandomForestClassifier())\n",
    "scores_1 = cross_validate(pipe_1, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "\n",
    "#y_pred_1 = cross_val_predict(pipe_1, X, y, cv=None) \n",
    "#confusion_matrix(y, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8878978a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10909224, 0.10742903, 0.1089108 , 0.10862112, 0.10711884]),\n",
       " 'score_time': array([0.02949715, 0.0291841 , 0.02995896, 0.02952194, 0.02939701]),\n",
       " 'test_accuracy': array([0.91390728, 0.90728477, 0.89333333, 0.93333333, 0.9       ]),\n",
       " 'test_roc_auc': array([0.73538961, 0.58668831, 0.55214286, 0.72535714, 0.63080445]),\n",
       " 'test_f1': array([0.13333333, 0.        , 0.        , 0.375     , 0.11764706]),\n",
       " 'test_precision': array([0.25      , 0.        , 0.        , 0.5       , 0.16666667]),\n",
       " 'test_recall': array([0.09090909, 0.        , 0.        , 0.3       , 0.09090909])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline 2 using mean/mode value imputation and random oversampling\n",
    "\n",
    "pipe_2 = make_pipeline(MeanImputationTransformer(), RandomOverSampler('minority'), RandomForestClassifier())\n",
    "scores_2 = cross_validate(pipe_2, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "scores_2\n",
    "\n",
    "#y_pred_2 = cross_val_predict(pipe_2, X, y, cv=None) \n",
    "#confusion_matrix(y, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbaff3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10962987, 0.10777307, 0.10829401, 0.10932899, 0.10658693]),\n",
       " 'score_time': array([0.01461983, 0.01436996, 0.01413798, 0.01478791, 0.01434278]),\n",
       " 'test_accuracy': array([0.9205298 , 0.91390728, 0.93333333, 0.94      , 0.88666667]),\n",
       " 'test_roc_auc': array([0.69480519, 0.5474026 , 0.51357143, 0.71964286, 0.58338784]),\n",
       " 'test_f1': array([0.14285714, 0.        , 0.        , 0.30769231, 0.10526316]),\n",
       " 'test_precision': array([0.33333333, 0.        , 0.        , 0.66666667, 0.125     ]),\n",
       " 'test_recall': array([0.09090909, 0.        , 0.        , 0.2       , 0.09090909])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline 3 using unique value imputation and smote oversampling\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=k, random_state=seed)\n",
    "\n",
    "pipe_3 = make_pipeline(SimpleImputer(fill_value=-99), sm, RandomForestClassifier())\n",
    "scores_3 = cross_validate(pipe_3, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "scores_3\n",
    "\n",
    "\n",
    "#y_pred_3 = cross_val_predict(pipe_3, X, y, cv=None) \n",
    "#confusion_matrix(y, y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0ec529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.11711407, 0.11458683, 0.11444092, 0.11547709, 0.11526823]),\n",
       " 'score_time': array([0.03003621, 0.0291059 , 0.02902794, 0.02936697, 0.03066492]),\n",
       " 'test_accuracy': array([0.91390728, 0.90066225, 0.93333333, 0.94      , 0.9       ]),\n",
       " 'test_roc_auc': array([0.63603896, 0.67727273, 0.47928571, 0.68678571, 0.55166776]),\n",
       " 'test_f1': array([0.13333333, 0.        , 0.        , 0.30769231, 0.11764706]),\n",
       " 'test_precision': array([0.25      , 0.        , 0.        , 0.66666667, 0.16666667]),\n",
       " 'test_recall': array([0.09090909, 0.        , 0.        , 0.2       , 0.09090909])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline 3 using mean/mode imputation and smote oversampling\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=k, random_state=seed)\n",
    "\n",
    "pipe_4 = make_pipeline(MeanImputationTransformer(), sm, RandomForestClassifier())\n",
    "scores_4 = cross_validate(pipe_4, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "scores_4\n",
    "\n",
    "#y_pred_4 = cross_val_predict(pipe_4, X, y, cv=None) \n",
    "#confusion_matrix(y, y_pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8da287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All pipelines for Gradient Boosting\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "                                 max_depth=1, random_state=seed)\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=k, random_state=seed)\n",
    "\n",
    "pipe_5 = make_pipeline(SimpleImputer(fill_value=-99), RandomOverSampler('minority'), clf)\n",
    "scores_5 = cross_validate(pipe_5, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "scores_5\n",
    "\n",
    "pipe_6 = make_pipeline(MeanImputationTransformer(), RandomOverSampler('minority'), clf)\n",
    "scores_6 = cross_validate(pipe_6, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "\n",
    "pipe_7 = make_pipeline(SimpleImputer(fill_value=-99), sm, clf)\n",
    "scores_7 = cross_validate(pipe_7, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "\n",
    "\n",
    "pipe_8 = make_pipeline(MeanImputationTransformer(), sm, clf)\n",
    "scores_8 = cross_validate(pipe_8, X, y, cv=cv, scoring=['accuracy','roc_auc','f1', 'precision','recall'])\n",
    "\n",
    "#y_pred_4 = cross_val_predict(pipe_4, X, y, cv=None) \n",
    "#confusion_matrix(y, y_pred_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ab248",
   "metadata": {},
   "source": [
    "**VISUALIZE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50e4a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_numbers = 2 # used for rounding\n",
    "\n",
    "combinations = [{'model':'Random forest', 'sampling':'random', 'imputation':'unique', 'scores':scores_1},\n",
    "                {'model':'Random forest', 'sampling':'random', 'imputation':'mean/mode', 'scores':scores_2},\n",
    "                {'model':'Random forest', 'sampling':'SMOTE', 'imputation':'unique', 'scores':scores_3},\n",
    "                {'model':'Random forest', 'sampling':'SMOTE', 'imputation':'mean/mode', 'scores':scores_4},\n",
    "                {'model':'Gradient boosting', 'sampling':'random', 'imputation':'unique', 'scores':scores_5},\n",
    "                {'model':'Gradient boosting', 'sampling':'random', 'imputation':'mean/mode', 'scores':scores_6},\n",
    "                {'model':'Gradient boosting', 'sampling':'SMOTE', 'imputation':'unique', 'scores':scores_7},\n",
    "                {'model':'Gradient boosting', 'sampling':'SMOTE', 'imputation':'mean/mode', 'scores':scores_8}]\n",
    "\n",
    "config_parameters = ['model', 'sampling', 'imputation']\n",
    "\n",
    "headers = [\"Model\", \"sampling\", \"imputation\", \"accuracy\", \"roc_auc\", \"f1\", \"precision\", \"recall\"]\n",
    "eval_metrics = ['test_accuracy', 'test_roc_auc', 'test_f1', 'test_precision', 'test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb31629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Model            </td><td>sampling</td><td>imputation</td><td>accuracy    </td><td>roc_auc     </td><td>f1          </td><td>precision   </td><td>recall      </td></tr>\n",
       "<tr><td>Random forest    </td><td>random  </td><td>unique    </td><td>0.91 +- 0.01</td><td>0.62 +- 0.09</td><td>0.11 +- 0.11</td><td>0.17 +- 0.18</td><td>0.08 +- 0.07</td></tr>\n",
       "<tr><td>Random forest    </td><td>random  </td><td>mean/mode </td><td>0.91 +- 0.01</td><td>0.65 +- 0.07</td><td>0.13 +- 0.14</td><td>0.18 +- 0.19</td><td>0.1 +- 0.11 </td></tr>\n",
       "<tr><td>Random forest    </td><td>SMOTE   </td><td>unique    </td><td>0.92 +- 0.02</td><td>0.61 +- 0.08</td><td>0.11 +- 0.11</td><td>0.22 +- 0.25</td><td>0.08 +- 0.07</td></tr>\n",
       "<tr><td>Random forest    </td><td>SMOTE   </td><td>mean/mode </td><td>0.92 +- 0.02</td><td>0.61 +- 0.08</td><td>0.11 +- 0.11</td><td>0.22 +- 0.24</td><td>0.08 +- 0.07</td></tr>\n",
       "<tr><td>Gradient boosting</td><td>random  </td><td>unique    </td><td>0.76 +- 0.03</td><td>0.57 +- 0.04</td><td>0.14 +- 0.05</td><td>0.09 +- 0.04</td><td>0.28 +- 0.11</td></tr>\n",
       "<tr><td>Gradient boosting</td><td>random  </td><td>mean/mode </td><td>0.79 +- 0.03</td><td>0.55 +- 0.04</td><td>0.17 +- 0.07</td><td>0.12 +- 0.05</td><td>0.3 +- 0.1  </td></tr>\n",
       "<tr><td>Gradient boosting</td><td>SMOTE   </td><td>unique    </td><td>0.87 +- 0.04</td><td>0.53 +- 0.06</td><td>0.13 +- 0.05</td><td>0.15 +- 0.08</td><td>0.13 +- 0.05</td></tr>\n",
       "<tr><td>Gradient boosting</td><td>SMOTE   </td><td>mean/mode </td><td>0.85 +- 0.03</td><td>0.55 +- 0.04</td><td>0.14 +- 0.05</td><td>0.12 +- 0.04</td><td>0.17 +- 0.08</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<tbody>\\n<tr><td>Model            </td><td>sampling</td><td>imputation</td><td>accuracy    </td><td>roc_auc     </td><td>f1          </td><td>precision   </td><td>recall      </td></tr>\\n<tr><td>Random forest    </td><td>random  </td><td>unique    </td><td>0.91 +- 0.01</td><td>0.62 +- 0.09</td><td>0.11 +- 0.11</td><td>0.17 +- 0.18</td><td>0.08 +- 0.07</td></tr>\\n<tr><td>Random forest    </td><td>random  </td><td>mean/mode </td><td>0.91 +- 0.01</td><td>0.65 +- 0.07</td><td>0.13 +- 0.14</td><td>0.18 +- 0.19</td><td>0.1 +- 0.11 </td></tr>\\n<tr><td>Random forest    </td><td>SMOTE   </td><td>unique    </td><td>0.92 +- 0.02</td><td>0.61 +- 0.08</td><td>0.11 +- 0.11</td><td>0.22 +- 0.25</td><td>0.08 +- 0.07</td></tr>\\n<tr><td>Random forest    </td><td>SMOTE   </td><td>mean/mode </td><td>0.92 +- 0.02</td><td>0.61 +- 0.08</td><td>0.11 +- 0.11</td><td>0.22 +- 0.24</td><td>0.08 +- 0.07</td></tr>\\n<tr><td>Gradient boosting</td><td>random  </td><td>unique    </td><td>0.76 +- 0.03</td><td>0.57 +- 0.04</td><td>0.14 +- 0.05</td><td>0.09 +- 0.04</td><td>0.28 +- 0.11</td></tr>\\n<tr><td>Gradient boosting</td><td>random  </td><td>mean/mode </td><td>0.79 +- 0.03</td><td>0.55 +- 0.04</td><td>0.17 +- 0.07</td><td>0.12 +- 0.05</td><td>0.3 +- 0.1  </td></tr>\\n<tr><td>Gradient boosting</td><td>SMOTE   </td><td>unique    </td><td>0.87 +- 0.04</td><td>0.53 +- 0.06</td><td>0.13 +- 0.05</td><td>0.15 +- 0.08</td><td>0.13 +- 0.05</td></tr>\\n<tr><td>Gradient boosting</td><td>SMOTE   </td><td>mean/mode </td><td>0.85 +- 0.03</td><td>0.55 +- 0.04</td><td>0.14 +- 0.05</td><td>0.12 +- 0.04</td><td>0.17 +- 0.08</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data.append(headers)\n",
    "\n",
    "for combination in combinations:\n",
    "    summary = [combination[param] for param in config_parameters]\n",
    "    \n",
    "    for metric in eval_metrics:\n",
    "        mean = combination['scores'][metric].mean().round(significant_numbers)\n",
    "        std = combination['scores'][metric].std().round(significant_numbers)\n",
    "        summary.append(f'{mean} +- {std}')\n",
    "        \n",
    "    data.append(summary)\n",
    "    \n",
    "table = tabulate.tabulate(data, tablefmt='html')\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
